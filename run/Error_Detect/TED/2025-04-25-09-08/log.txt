Learning Rate: 0.001
Epochs: 30
Batch Size: 1
Weight Decay: 0.0001
Model Architecture: TED
Loss Function: Fl
Optimizer: Adam
lr_scheduler: StepLR, step_size=10, gamma=0.1
Data_root: ../data/error_detect_data/train, ../data/error_detect_data/test
Start training...
Train_1: loss: 0.2461, Precision: 0.3031, Recall: 0.5359, 'F1:' 0.3872
Valid_1: loss: 0.2973, Precision: 0.5128, Recall: 0.4361, 'F1:' 0.4714

Train_2: loss: 0.2182, Precision: 0.3496, Recall: 0.5827, 'F1:' 0.4370
Valid_2: loss: 0.2459, Precision: 0.5174, Recall: 0.4174, 'F1:' 0.4621

Train_3: loss: 0.2115, Precision: 0.3442, Recall: 0.6275, 'F1:' 0.4445
Valid_3: loss: 0.2370, Precision: 0.4904, Recall: 0.5545, 'F1:' 0.5205

Train_4: loss: 0.2196, Precision: 0.3600, Recall: 0.6285, 'F1:' 0.4577
Valid_4: loss: 0.2432, Precision: 0.4219, Recall: 0.6480, 'F1:' 0.5111

Train_5: loss: 0.2417, Precision: 0.3700, Recall: 0.6087, 'F1:' 0.4603
Valid_5: loss: 0.2684, Precision: 0.3610, Recall: 0.7445, 'F1:' 0.4863

Train_6: loss: 0.2653, Precision: 0.3891, Recall: 0.5879, 'F1:' 0.4683
Valid_6: loss: 0.3645, Precision: 0.5339, Recall: 0.3925, 'F1:' 0.4524

Train_7: loss: 0.3148, Precision: 0.4268, Recall: 0.4641, 'F1:' 0.4447
Valid_7: loss: 0.2736, Precision: 0.4072, Recall: 0.6355, 'F1:' 0.4963

Train_8: loss: 0.2431, Precision: 0.3601, Recall: 0.5838, 'F1:' 0.4454
Valid_8: loss: 0.2591, Precision: 0.4259, Recall: 0.5732, 'F1:' 0.4887

Train_9: loss: 0.2771, Precision: 0.3697, Recall: 0.5213, 'F1:' 0.4326
Valid_9: loss: 0.3151, Precision: 0.4220, Recall: 0.5732, 'F1:' 0.4861

Train_10: loss: 0.2791, Precision: 0.3916, Recall: 0.5848, 'F1:' 0.4691
Valid_10: loss: 0.2966, Precision: 0.4226, Recall: 0.6293, 'F1:' 0.5056

Train_11: loss: 0.2838, Precision: 0.3671, Recall: 0.5879, 'F1:' 0.4520
Valid_11: loss: 0.3024, Precision: 0.4270, Recall: 0.6012, 'F1:' 0.4993

Train_12: loss: 0.2867, Precision: 0.3925, Recall: 0.5567, 'F1:' 0.4604
Valid_12: loss: 0.3050, Precision: 0.4450, Recall: 0.5545, 'F1:' 0.4938

Train_13: loss: 0.2785, Precision: 0.3987, Recall: 0.5713, 'F1:' 0.4696
Valid_13: loss: 0.3059, Precision: 0.4372, Recall: 0.5857, 'F1:' 0.5007

Train_14: loss: 0.2856, Precision: 0.3957, Recall: 0.5588, 'F1:' 0.4633
Valid_14: loss: 0.3066, Precision: 0.4500, Recall: 0.5327, 'F1:' 0.4879

Train_15: loss: 0.2829, Precision: 0.4141, Recall: 0.5494, 'F1:' 0.4723
Valid_15: loss: 0.3059, Precision: 0.4613, Recall: 0.5576, 'F1:' 0.5049

Train_16: loss: 0.2841, Precision: 0.4005, Recall: 0.5546, 'F1:' 0.4651
Valid_16: loss: 0.3067, Precision: 0.4477, Recall: 0.5732, 'F1:' 0.5027

Train_17: loss: 0.2836, Precision: 0.3996, Recall: 0.5692, 'F1:' 0.4695
Valid_17: loss: 0.3040, Precision: 0.4519, Recall: 0.5857, 'F1:' 0.5102

Train_18: loss: 0.2733, Precision: 0.3972, Recall: 0.6129, 'F1:' 0.4820
Valid_18: loss: 0.3041, Precision: 0.4416, Recall: 0.5888, 'F1:' 0.5047

